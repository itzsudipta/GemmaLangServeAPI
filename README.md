# ğŸš€ GemmaLangServeAPI

**GemmaLangServeAPI** is a FastAPI-powered API service built using **Google's Gemma 2B LLM** integrated through **LangChain** and **LangServe**. It allows users to submit Python code and receive human-like explanations in response â€” ideal for educational, debugging, or AI-assistance use cases.

Hosted via **ngrok** for easy sharing and accessible testing through **Postman**.

---

## ğŸ“Œ Features

- ğŸ§  Explains Python functions in natural language
- ğŸ”— Easily deployable via FastAPI + LangServe
- âš¡ Supports Hugging Face Gemma 2B model pipeline
- ğŸ§ª API testing-ready via Postman or Swagger UI
- â˜ï¸ Hosted via Google Colab with public URL through ngrok

---

## ğŸ› ï¸ Tech Stack

| Layer               | Technology / Tool                                                                 |
|---------------------|----------------------------------------------------------------------------------|
| **API Framework**   | [FastAPI](https://fastapi.tiangolo.com/)                                          |
| **LLM**             | [Gemma 2B](https://huggingface.co/google/gemma-2b) by Google                      |
| **Model Pipeline**  | [HuggingFace Transformers](https://huggingface.co/transformers)                   |
| **Orchestration**   | [LangChain](https://www.langchain.com/) + [LangServe](https://docs.langchain.com/) |
| **Serving**         | [Uvicorn](https://www.uvicorn.org/)                                               |
| **Tunneling**       | [ngrok](https://ngrok.com/)                                                       |
| **LLM Wrapper**     | [HuggingFacePipeline](https://api.python.langchain.com/en/latest/huggingface.html)|
| **Test Tool**       | [Postman](https://www.postman.com/)                                               |
| **Platform**        | [Google Colab](https://colab.research.google.com/)                                |

---

## ğŸš€ How to Run

### ğŸ§± Prerequisites

Install dependencies:

```bash
pip install fastapi uvicorn transformers langchain langserve langchain_huggingface huggingface_hub pyngrok nest_asyncio
```

### â–¶ï¸ Run the Server

```bash
python app.py
```

Youâ€™ll get a public URL via ngrok, like:

```
ğŸ”— https://your-subdomain.ngrok-free.app/docs
```

Open the `/docs` route to explore Swagger UI or test it using Postman.

---

## ğŸ“® Postman API Guide

| Method | Endpoint   | Description                        |
|--------|------------|------------------------------------|
| POST   | /explain   | Submit Python code for explanation |

### ğŸ§¾ Headers

```
Content-Type: application/json
```

### ğŸ“¤ Request Body

```json
{
  "code": "def add(a, b): return a + b"
}
```

### âœ… Example Response

```json
{
  "output": "This function takes two parameters and returns their sum."
}
```

---

## ğŸ§© Project Structure

```
GemmaLangServeAPI/
â”œâ”€â”€ app.py            # FastAPI + LangChain setup
â”œâ”€â”€ requirements.txt  # All dependencies
â””â”€â”€ README.md         # You're reading it!
```

---

## ğŸ“š Use Cases

- ğŸ‘¨â€ğŸ’» Educational tools or tutorials
- ğŸ§  AI-powered code explanation service
- ğŸ¤– Backend service for developer assistance tools

---

## ğŸ“ License

This project is licensed under the MIT License.

---

## ğŸ™ Acknowledgements

- ğŸ¤– Google AI â€“ Gemma LLM
- ğŸ§± LangChain
- ğŸ¤— Hugging Face
- âš¡ FastAPI
